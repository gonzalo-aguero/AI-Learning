{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8484576",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "access_token = os.getenv(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    "    token=access_token\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25115fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_markdown(text):\n",
    "    html = markdown.markdown(text, extensions=['fenced_code', 'codehilite'])\n",
    "    html = f\"<div class='markdown-body'>{html}</div>\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a45f2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "access_token = os.getenv(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"fireworks-ai\",\n",
    "    api_key=os.environ[\"HUGGING_FACE_HUB_TOKEN\"],\n",
    ")\n",
    "\n",
    "prompt = \"Teach me how to create an AI agent using the Llama 3.1 model and Langchain.\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Please format the code within Markdown code blocks, using \\\"~~~\\\". For example:\\n\"\n",
    "                \"~~~python\\nprint('Hello, world!')\\n~~~.\\n\"\n",
    "                + prompt\n",
    "            )\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "message_content = completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d217bc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='markdown-body'><p>Creating an AI agent using the Llama 3.1 model and Langchain involves several steps. Here's a high-level overview of the process and some sample code to get you started:</p>\n",
       "<h3>Step 1: Install Required Libraries</h3>\n",
       "<p>First, you need to install the required libraries, including Langchain and the Llama 3.1 model.</p>\n",
       "<div class=\"codehilite\"><pre><span></span><code>pip<span class=\"w\"> </span>install<span class=\"w\"> </span>langchain\n",
       "pip<span class=\"w\"> </span>install<span class=\"w\"> </span>llama\n",
       "</code></pre></div>\n",
       "\n",
       "<h3>Step 2: Import Libraries and Initialize the Llama Model</h3>\n",
       "<p>Next, import the necessary libraries and initialize the Llama 3.1 model.</p>\n",
       "<div class=\"codehilite\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">langchain</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">langchain.llms</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">LLaMA</span>\n",
       "\n",
       "<span class=\"c1\"># Initialize the Llama 3.1 model</span>\n",
       "<span class=\"n\">llama_model</span> <span class=\"o\">=</span> <span class=\"n\">LLaMA</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"o\">=</span><span class=\"s2\">&quot;YOUR_LLAma_API_KEY&quot;</span><span class=\"p\">)</span>\n",
       "</code></pre></div>\n",
       "\n",
       "<p>Replace \"YOUR_LLAma_API_KEY\" with your actual Llama API key.</p>\n",
       "<h3>Step 3: Create a Langchain Agent</h3>\n",
       "<p>Create a Langchain agent using the initialized Llama model.</p>\n",
       "<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># Create a Langchain agent</span>\n",
       "<span class=\"n\">agent</span> <span class=\"o\">=</span> <span class=\"n\">langchain</span><span class=\"o\">.</span><span class=\"n\">agents</span><span class=\"o\">.</span><span class=\"n\">LLMAgent</span><span class=\"p\">(</span><span class=\"n\">llama_model</span><span class=\"o\">=</span><span class=\"n\">llama_model</span><span class=\"p\">)</span>\n",
       "</code></pre></div>\n",
       "\n",
       "<h3>Step 4: Define a Task</h3>\n",
       "<p>Define a task for the agent to perform. For example, you can ask it to generate a response to a given prompt.</p>\n",
       "<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># Define a task</span>\n",
       "<span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;Write a short story about a character who discovers a hidden world.&quot;</span>\n",
       "</code></pre></div>\n",
       "\n",
       "<h3>Step 5: Execute the Task</h3>\n",
       "<p>Finally, execute the task using the agent.</p>\n",
       "<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># Execute the task</span>\n",
       "<span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">agent</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"o\">=</span><span class=\"n\">task</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Print the response</span>\n",
       "<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>\n",
       "</code></pre></div>\n",
       "\n",
       "<h3>Full Code Example</h3>\n",
       "<p>Here's the full code example:</p>\n",
       "<div class=\"codehilite\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">langchain</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">langchain.llms</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">LLaMA</span>\n",
       "\n",
       "<span class=\"c1\"># Initialize the Llama 3.1 model</span>\n",
       "<span class=\"n\">llama_model</span> <span class=\"o\">=</span> <span class=\"n\">LLaMA</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"o\">=</span><span class=\"s2\">&quot;YOUR_LLAma_API_KEY&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Create a Langchain agent</span>\n",
       "<span class=\"n\">agent</span> <span class=\"o\">=</span> <span class=\"n\">langchain</span><span class=\"o\">.</span><span class=\"n\">agents</span><span class=\"o\">.</span><span class=\"n\">LLMAgent</span><span class=\"p\">(</span><span class=\"n\">llama_model</span><span class=\"o\">=</span><span class=\"n\">llama_model</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Define a task</span>\n",
       "<span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;Write a short story about a character who discovers a hidden world.&quot;</span>\n",
       "\n",
       "<span class=\"c1\"># Execute the task</span>\n",
       "<span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">agent</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"o\">=</span><span class=\"n\">task</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Print the response</span>\n",
       "<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>\n",
       "</code></pre></div>\n",
       "\n",
       "<p>Replace \"YOUR_LLAma_API_KEY\" with your actual Llama API key.</p>\n",
       "<p>Note that this is just a basic example to get you started. You can customize the agent and tasks to suit your specific needs. Additionally, you may want to consider using a more robust task execution mechanism, such as a task queue or a workflow manager.</p></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(message_content)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d020e40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Creating an AI agent using the Llama 3.1 model and Langchain involves several steps. Here\\'s a high-level overview of the process and some sample code to get you started:\\n\\n### Step 1: Install Required Libraries\\n\\nFirst, you need to install the required libraries, including Langchain and the Llama 3.1 model.\\n\\n~~~bash\\npip install langchain\\npip install llama\\n~~~\\n\\n### Step 2: Import Libraries and Initialize the Llama Model\\n\\nNext, import the necessary libraries and initialize the Llama 3.1 model.\\n\\n~~~python\\nimport langchain\\nfrom langchain.llms import LLaMA\\n\\n# Initialize the Llama 3.1 model\\nllama_model = LLaMA(key=\"YOUR_LLAma_API_KEY\")\\n~~~\\n\\nReplace \"YOUR_LLAma_API_KEY\" with your actual Llama API key.\\n\\n### Step 3: Create a Langchain Agent\\n\\nCreate a Langchain agent using the initialized Llama model.\\n\\n~~~python\\n# Create a Langchain agent\\nagent = langchain.agents.LLMAgent(llama_model=llama_model)\\n~~~\\n\\n### Step 4: Define a Task\\n\\nDefine a task for the agent to perform. For example, you can ask it to generate a response to a given prompt.\\n\\n~~~python\\n# Define a task\\ntask = \"Write a short story about a character who discovers a hidden world.\"\\n~~~\\n\\n### Step 5: Execute the Task\\n\\nFinally, execute the task using the agent.\\n\\n~~~python\\n# Execute the task\\nresponse = agent(task=task)\\n\\n# Print the response\\nprint(response)\\n~~~\\n\\n### Full Code Example\\n\\nHere\\'s the full code example:\\n\\n~~~python\\nimport langchain\\nfrom langchain.llms import LLaMA\\n\\n# Initialize the Llama 3.1 model\\nllama_model = LLaMA(key=\"YOUR_LLAma_API_KEY\")\\n\\n# Create a Langchain agent\\nagent = langchain.agents.LLMAgent(llama_model=llama_model)\\n\\n# Define a task\\ntask = \"Write a short story about a character who discovers a hidden world.\"\\n\\n# Execute the task\\nresponse = agent(task=task)\\n\\n# Print the response\\nprint(response)\\n~~~\\n\\nReplace \"YOUR_LLAma_API_KEY\" with your actual Llama API key.\\n\\nNote that this is just a basic example to get you started. You can customize the agent and tasks to suit your specific needs. Additionally, you may want to consider using a more robust task execution mechanism, such as a task queue or a workflow manager.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
