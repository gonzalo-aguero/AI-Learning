{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61be766a",
   "metadata": {},
   "source": [
    "## 1. Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7621dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b7b81",
   "metadata": {},
   "source": [
    "## 2. Configuración de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración general\n",
    "EPOCHS = 10\n",
    "IMG_WIDTH = 30\n",
    "IMG_HEIGHT = 30\n",
    "NUM_CATEGORIES = 43\n",
    "TEST_SIZE = 0.4\n",
    "\n",
    "# Hiperparámetros del modelo\n",
    "LEARNING_RATE = 0.001\n",
    "FILTERS = 16\n",
    "KERNEL_SIZE = 3\n",
    "DENSE1 = 256\n",
    "DENSE2 = 256\n",
    "DENSE3 = 256\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# Ruta de datos (ajustar según sea necesario)\n",
    "DATA_DIR = \"./gtsrb\"  # Cambiar a la ruta de tus datos\n",
    "\n",
    "print(\"Configuración:\")\n",
    "print(f\"- Épocas: {EPOCHS}\")\n",
    "print(f\"- Tamaño de imagen: {IMG_WIDTH}x{IMG_HEIGHT}\")\n",
    "print(f\"- Categorías: {NUM_CATEGORIES}\")\n",
    "print(f\"- Test size: {TEST_SIZE}\")\n",
    "print(f\"- Learning rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2270ebb0",
   "metadata": {},
   "source": [
    "## 3. Funciones de Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d197eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    \"\"\"\n",
    "    Load image data from directory `data_dir`.\n",
    "\n",
    "    Assume `data_dir` has one directory named after each category, numbered\n",
    "    0 through NUM_CATEGORIES - 1. Inside each category directory will be some\n",
    "    number of image files.\n",
    "\n",
    "    Return tuple `(images, labels)`. `images` should be a list of all\n",
    "    of the images in the data directory, where each image is formatted as a\n",
    "    numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. `labels` should\n",
    "    be a list of integer labels, representing the categories for each of the\n",
    "    corresponding `images`.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for category in os.listdir(data_dir):\n",
    "        category_dir = os.path.join(data_dir, str(category))\n",
    "        if not os.path.isdir(category_dir):\n",
    "            continue\n",
    "            \n",
    "        for filename in os.listdir(category_dir):\n",
    "            img_path = os.path.join(category_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))            \n",
    "            images.append(img)\n",
    "            labels.append(int(category))\n",
    "    \n",
    "    print(f\"Carga de imágenes completada: {len(images)} imágenes.\")\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5949d67",
   "metadata": {},
   "source": [
    "## 4. Cargar y Preparar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbee21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "images, labels = load_data(DATA_DIR)\n",
    "print(f\"Set de {len(images)} imágenes cargadas.\")\n",
    "\n",
    "# Convertir labels a categorical\n",
    "labels = tf.keras.utils.to_categorical(labels, num_classes=NUM_CATEGORIES)\n",
    "\n",
    "# Split en train y test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(images), np.array(labels), test_size=TEST_SIZE, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nDatos de entrenamiento: {x_train.shape}\")\n",
    "print(f\"Labels de entrenamiento: {y_train.shape}\")\n",
    "print(f\"Datos de prueba: {x_test.shape}\")\n",
    "print(f\"Labels de prueba: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacebf80",
   "metadata": {},
   "source": [
    "### Visualizar algunas imágenes de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar algunas imágenes del dataset\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle('Ejemplos de Imágenes de Entrenamiento', fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Convertir de BGR a RGB para visualización correcta\n",
    "    img_rgb = cv2.cvtColor(x_train[i], cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(img_rgb)\n",
    "    ax.set_title(f'Categoría: {np.argmax(y_train[i])}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775cb1c0",
   "metadata": {},
   "source": [
    "## 5. Definir el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86339c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    Returns a compiled convolutional neural network model. Assume that the\n",
    "    `input_shape` of the first layer is `(IMG_WIDTH, IMG_HEIGHT, 3)`.\n",
    "    The output layer should have `NUM_CATEGORIES` units, one for each category.\n",
    "    \"\"\"\n",
    "    # Create a convolutional neural network\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Convolutional layer. It will learn filters using a kernel\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters=FILTERS, \n",
    "            kernel_size=(KERNEL_SIZE, KERNEL_SIZE), \n",
    "            activation=\"relu\", \n",
    "            input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "        ),\n",
    "\n",
    "        # Flatten units\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        # Add hidden layers with dropout\n",
    "        tf.keras.layers.Dense(DENSE1, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Dense(DENSE2, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Dense(DENSE3, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "\n",
    "        # Add an output layer with output units for all categories\n",
    "        tf.keras.layers.Dense(NUM_CATEGORIES, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d25ca0",
   "metadata": {},
   "source": [
    "### Crear y visualizar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef1612e",
   "metadata": {},
   "source": [
    "## 6. Entrenar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nEntrenamiento completado en {training_time:.2f} segundos ({training_time/60:.2f} minutos).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ac0977",
   "metadata": {},
   "source": [
    "## 7. Visualizar Resultados del Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41657f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar accuracy y loss\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "if 'val_accuracy' in history.history:\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss\n",
    "ax2.plot(history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030943f",
   "metadata": {},
   "source": [
    "## 8. Evaluar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate neural network performance\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"RESULTADOS EN TEST SET\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d95ca",
   "metadata": {},
   "source": [
    "## 9. Guardar el Modelo y Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log_data(history, training_time, test_accuracy, test_loss, log_file='training_log.json'):\n",
    "    \"\"\"\n",
    "    Saves the log data from training and testing into a JSON file.\n",
    "    \n",
    "    Parameters:\n",
    "    - history (tf.keras.callbacks.History): The history object containing the training history.\n",
    "    - training_time (float): Time taken to train the model in seconds.\n",
    "    - test_accuracy (float): The accuracy of the model on the test dataset.\n",
    "    - test_loss (float): The loss of the model on the test dataset.\n",
    "    - log_file (str): The path to the JSON file where the log data will be saved.\n",
    "    \n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    # Cargar el contenido existente del archivo o inicializar un array vacío\n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, 'r') as file:\n",
    "            try:\n",
    "                log_data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                log_data = []\n",
    "    else:\n",
    "        log_data = []\n",
    "\n",
    "    # Extraer los hiperparámetros y resultados del historial de entrenamiento\n",
    "    new_log_entry = {\n",
    "        \"hyperparameters\": {\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"filters\": FILTERS,\n",
    "            \"kernel_size\": KERNEL_SIZE,\n",
    "            \"dense1\": DENSE1,\n",
    "            \"dense2\": DENSE2,\n",
    "            \"dense3\": DENSE3,\n",
    "            \"dropout\": DROPOUT\n",
    "        },\n",
    "        \"results\": {\n",
    "            \"train_accuracy\": float(history.history['accuracy'][-1]),\n",
    "            \"train_loss\": float(history.history['loss'][-1]),\n",
    "            \"test_accuracy\": float(test_accuracy),\n",
    "            \"test_loss\": float(test_loss),\n",
    "            \"training_time\": round(training_time, 3)\n",
    "        }\n",
    "    }\n",
    "    log_data.append(new_log_entry)\n",
    "\n",
    "    # Escribir el array completo de nuevo en el archivo\n",
    "    with open(log_file, 'w') as file:\n",
    "        json.dump(log_data, file, indent=4)\n",
    "    \n",
    "    print(f\"\\nLogs guardados en: {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef23ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "model_filename = \"model.keras\"\n",
    "model.save(model_filename)\n",
    "print(f\"Modelo guardado en: {model_filename}\")\n",
    "\n",
    "# Guardar los logs\n",
    "log_filename = \"training_log_notebook.json\"\n",
    "save_log_data(history, training_time, test_accuracy, test_loss, log_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d876c3",
   "metadata": {},
   "source": [
    "## 10. Predicciones de Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b078560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones en algunas imágenes de prueba\n",
    "num_examples = 10\n",
    "predictions = model.predict(x_test[:num_examples])\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test[:num_examples], axis=1)\n",
    "\n",
    "# Visualizar predicciones\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle('Predicciones del Modelo', fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img_rgb = cv2.cvtColor(x_test[i], cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(img_rgb)\n",
    "    \n",
    "    color = 'green' if predicted_classes[i] == true_classes[i] else 'red'\n",
    "    ax.set_title(f'Real: {true_classes[i]}\\nPred: {predicted_classes[i]}', color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcular accuracy en estos ejemplos\n",
    "correct = np.sum(predicted_classes == true_classes)\n",
    "print(f\"\\nPrecisión en los {num_examples} ejemplos: {correct}/{num_examples} ({correct/num_examples*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0583a9",
   "metadata": {},
   "source": [
    "## 11. Análisis de Resultados\n",
    "\n",
    "### Resumen de Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4033611",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMEN COMPLETO DEL ENTRENAMIENTO\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nHIPERPARÁMETROS:\")\n",
    "print(f\"  - Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Épocas: {EPOCHS}\")\n",
    "print(f\"  - Filtros Conv: {FILTERS}\")\n",
    "print(f\"  - Kernel Size: {KERNEL_SIZE}x{KERNEL_SIZE}\")\n",
    "print(f\"  - Dense Layers: {DENSE1}, {DENSE2}, {DENSE3}\")\n",
    "print(f\"  - Dropout: {DROPOUT}\")\n",
    "print(\"\\nRESULTADOS DE ENTRENAMIENTO:\")\n",
    "print(f\"  - Train Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"  - Train Loss: {history.history['loss'][-1]:.4f}\")\n",
    "if 'val_accuracy' in history.history:\n",
    "    print(f\"  - Val Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "    print(f\"  - Val Loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "print(\"\\nRESULTADOS DE PRUEBA:\")\n",
    "print(f\"  - Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"  - Test Loss: {test_loss:.4f}\")\n",
    "print(f\"\\nTiempo de entrenamiento: {training_time:.2f} segundos\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
